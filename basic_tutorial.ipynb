{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4847d74d-ecdf-463f-a144-c6085837d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import pipeline\n",
    "import faiss\n",
    "import numpy as np\n",
    "import sentencepiece\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943cc9e3-8721-4afc-874b-582d672a75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pre-trained sentence transformer for embeddings\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66de1cac-3df8-4b87-8cf1-a3a9fc445522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample documents\n",
    "documents = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Python is a programming language widely used for machine learning.\",\n",
    "    \"The Great Wall of China is visible from space.\",\n",
    "    \"Water boils at 100 degrees Celsius under standard atmospheric pressure.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd22480b-9e95-42cb-9431-f7dde6ebf636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: embed and index the documents\n",
    "document_embeddings = embedder.encode(documents)\n",
    "dimension = document_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145bca5e-03f0-4d2b-b86f-da16049b03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a faiss index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(document_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb69e591-709d-46e0-a489-ae9a2f06d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: set up the generation model\n",
    "model_name = \"t5-small\"\n",
    "generator = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6387ed32-e33f-4148-8021-d7773d77fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_k=2):\n",
    "    # retrieve the top_k relevant documents for a query.\n",
    "    query_embedding = embedder.encode([query])\n",
    "    distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "    \n",
    "    # debugging\n",
    "    print(f\"Distances: {distances}\")\n",
    "    print(f\"Indices: {indices}\")\n",
    "    \n",
    "    # check if any results are returned\n",
    "    if len(indices[0]) == 0:\n",
    "        return [] # return empty list if no results are found\n",
    "\n",
    "    # debugging\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        print(f\"Index: {idx}, Distance: {distances[0][i]}, Document: {documents[idx]}\")\n",
    "        \n",
    "    return [(documents[idx], distances[0][i]) for i, idx in enumerate(indices[0]) if idx < len(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d84cea4-1e43-44a7-8cb8-a36eb824ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query):\n",
    "    # generate a response using retrieved documents as a context.\n",
    "    retrieved_docs = retrieve(query)\n",
    "    context = \" \".join([doc[0] for doc in retrieved_docs])\n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    # generate response\n",
    "    outputs = generator.generate(input_ids, max_length=50, num_beams=2, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e26d4cc-d141-4183-92e0-58f25ac8b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [[0.24197832 1.7641159 ]]\n",
      "Indices: [[0 1]]\n",
      "Index: 0, Distance: 0.24197831749916077, Document: The capital of France is Paris.\n",
      "Index: 1, Distance: 1.7641159296035767, Document: Python is a programming language widely used for machine learning.\n",
      "Query: What is the capital of France?\n",
      "Response: Paris\n"
     ]
    }
   ],
   "source": [
    "# test the RAG system\n",
    "query = \"What is the capital of France?\"\n",
    "response = generate_response(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60dbd518-ee49-4fea-a1bc-8f2ffbfaab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [[0.5197036 1.9164784]]\n",
      "Indices: [[1 0]]\n",
      "Index: 1, Distance: 0.5197036266326904, Document: Python is a programming language widely used for machine learning.\n",
      "Index: 0, Distance: 1.9164783954620361, Document: The capital of France is Paris.\n",
      "Query: Is python important?\n",
      "Response: widely used for machine learning\n"
     ]
    }
   ],
   "source": [
    "query = \"Is python important?\"\n",
    "response = generate_response(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770a0dc5-d144-4384-94ee-55a72f8a155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10325703,  0.03042013,  0.0290958 , ...,  0.05853158,\n",
       "         0.08585993, -0.0056698 ],\n",
       "       [-0.0504921 ,  0.00360606, -0.02291742, ...,  0.11549734,\n",
       "         0.14984636,  0.03146859],\n",
       "       [ 0.04052198,  0.07120404,  0.0485715 , ...,  0.01960546,\n",
       "        -0.09164685,  0.07383972],\n",
       "       [-0.04159974,  0.0122102 , -0.04180289, ...,  0.04172173,\n",
       "        -0.03254224,  0.03809972]], shape=(4, 384), dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8714acc-ddbe-4752-a64a-47e34ec72e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docuemnts: 4\n",
      "FAISS index size: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of docuemnts: {len(documents)}\")\n",
    "print(f\"FAISS index size: {index.ntotal}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d6ceb3-731a-42dd-b577-4d6683e25645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main argument of the document is to highlight the role and importance of the Open Source Initiative (OSI) in promoting, advocating for, and supporting open source software. It emphasizes the benefits of open source, such as higher quality, better reliability, greater flexibility, lower cost, and avoiding vendor lock-in. The OSI is presented as a key organization in building communities and standards in the open source ecosystem, helping to ensure that the freedoms and opportunities of open source software are accessible and beneficial to all.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Set up OpenAI API key if using GPT-4\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\"\n",
    "\n",
    "# Load the Paper\n",
    "with open(\"test_article.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    paper_text = f.read()\n",
    "\n",
    "# Chunking the Document\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(paper_text)\n",
    "\n",
    "# Create embeddings (Using Hugging Face to avoid OpenAI costs)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert text chunks into vector store\n",
    "vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Given the following documents, answer the question:\\n\\n{context}\\n\\nQuestion: {input}\"\n",
    ")\n",
    "\n",
    "# Use GPT-4 for synthesis\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# Create a document combination chain\n",
    "combine_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the RAG retrieval chain\n",
    "rag_chain = create_retrieval_chain(retriever, combine_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804da1e7-88db-4800-bdd0-00f4622cdd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main argument of this paper?\"\n",
    "response = rag_chain.invoke({\"input\": query})  # âœ… FIXED\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822ed554-56bf-4b42-b4dd-e50749531694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4.5-preview', 'omni-moderation-2024-09-26', 'gpt-4.5-preview-2025-02-27', 'gpt-4o-mini-audio-preview-2024-12-17', 'dall-e-3', 'dall-e-2', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview', 'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4o-mini-realtime-preview', 'o1-mini-2024-09-12', 'o1-preview-2024-09-12', 'o1-mini', 'o1-preview', 'gpt-4o-mini-audio-preview', 'whisper-1', 'gpt-4-turbo', 'gpt-4o-realtime-preview-2024-10-01', 'gpt-4', 'text-embedding-3-large', 'babbage-002', 'chatgpt-4o-latest', 'tts-1-hd-1106', 'gpt-4o-audio-preview-2024-12-17', 'tts-1-hd', 'gpt-4o-mini-2024-07-18', 'tts-1', 'tts-1-1106', 'gpt-4-turbo-2024-04-09', 'gpt-4o-2024-11-20', 'davinci-002', 'gpt-3.5-turbo-1106', 'gpt-4o-2024-08-06', 'gpt-4o-mini', 'gpt-4o-2024-05-13', 'gpt-3.5-turbo-instruct', 'gpt-4o', 'gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo-0125', 'gpt-4o-realtime-preview-2024-12-17', 'gpt-3.5-turbo', 'gpt-4o-realtime-preview', 'gpt-3.5-turbo-16k', 'gpt-4-0125-preview', 'text-embedding-3-small', 'text-embedding-ada-002', 'gpt-4-1106-preview', 'gpt-4-0613', 'gpt-4-turbo-preview', 'omni-moderation-latest']\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"your_api_key\"\n",
    "\n",
    "# Llist available models\n",
    "models = openai.models.list()\n",
    "\n",
    "print([model.id for model in models.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75794d01-fdf1-4837-b7c6-3f1cbda2cc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
